---
title: "Manneken Pis Data Wrangling"
format: html
execute:
  echo: true
  
---

Who is [Manneken Pis](https://en.wikipedia.org/wiki/Manneken_Pis)? He's got a lot of costumes, and I couldn't find a dataset anywhere that listed all the costumes. I felt that one needed to exist. 

Trying to get data from website, or premade database or scraping was a nightmare (selenium, Docker, UGH.) So, went hunting through HTML manually and found some long lists with all the costume info (both the full descriptions of the costumes, plus reference values for theme and geo location). Parsing/assembling together here. 

Link to google sheet with ref info (downloaded as xlsx) [here](https://docs.google.com/spreadsheets/d/1kz5t3EYrJ6qB2KBNBfarrR4SGkfJBC8ErjHw4ajHjBE/edit?usp=sharing)

All costumes found/scraped from this [site](https://www.mannekenpis.brussels/en/more-than-1000-costumes)

```{r}
#| output: false
library(jsonlite)
library(tidyverse)

# Saved this xlsx from google sheets -- get ref info on geo and theme IDs 
ref_theme <- readxl::read_xlsx('manneken-pis-costumes-ref.xlsx',sheet='theme') %>%
  separate(name,into = c('trash','id','wip'),sep = "\"") %>%
  separate(wip, into = c('trash2','theme','trash3','trash4'),sep=">|<") %>%
  select(-starts_with('trash'))

ref_geo <- readxl::read_xlsx('manneken-pis-costumes-ref.xlsx',sheet='geography') %>%
  separate(name,into = c('trash','id','wip'),sep = "\"") %>%
  separate(wip, into = c('trash2','geo','trash3','trash4'),sep=">|<") %>%
  select(-starts_with('trash'))

# Load JSONs from file, parse + merge into one df, with ref info attached
costume_theme <- fromJSON("/Users/carobuck/Documents/fun_projects/manneken-pis/theme_to_costumes.json")
costume_location <- fromJSON('/Users/carobuck/Documents/fun_projects/manneken-pis/location_to_costumes.json')

# deal w/ themes
list_of_dfs_no_extra <- lapply(costume_theme, function(df) {
  df[, !names(df) %in% c("t_s")]
})
list_of_dfs_with_id <- imap(list_of_dfs_no_extra, ~ mutate(.x, id_theme = .y))
combined_df_costume <- bind_rows(list_of_dfs_with_id)

# deal w/ geo
list_of_dfs_no_extra <- lapply(costume_location, function(df) {
  df %>% mutate(body = as.character(body)) %>%
    select(-t_s) -> df
  return(df)
})
list_of_dfs_with_id <- imap(list_of_dfs_no_extra, ~ mutate(.x, id_geo = .y))
combined_df_geo <- bind_rows(list_of_dfs_with_id)

# combine + clean up df
combined_df_costume %>%
  full_join(combined_df_geo) %>%
  full_join(ref_geo,by=join_by(id_geo==id)) %>%
  full_join(ref_theme,by=join_by(id_theme==id)) %>%
  mutate(t = str_trim(t),
         body = str_trim(body)) %>%
  distinct() -> clean_data
```

----

Get a glimpse of what the data look like now: 
```{r}
clean_data %>% glimpse()
```

----

Make some quick charts from the data
```{r}
library(treemapify)
clean_data %>%
  #count(geo,theme) %>%
  count(theme) %>%
  filter(!is.na(theme)) %>%
  ggplot(aes(y=n,x=fct_rev(fct_reorder(theme,n)))) +
  geom_col(fill='cyan4',color='gray30') +
  geom_label(aes(label=n),hjust = -0.1) +
  coord_flip() +
  theme_bw() +
  labs(y='Number of Costumes',x='',title='Costumes by Themed Category') +
  theme(axis.text = element_text(size=11)) 

clean_data %>%
  #count(geo,theme) %>%
  count(geo) %>%
  filter(n>=10) %>%
  ggplot(aes(area = n, fill = geo, label = paste(n,geo))) +
  geom_treemap(color='white') +
  geom_treemap_text(colour = "black",
                    place = "centre",
                    size = 15) +
  theme(legend.position = 'none') +
  labs(title='Locations with at least 10 Outfits')
```

---

Get stats for total number of locations and # themes
```{r}
clean_data %>%
  count(theme)

clean_data %>%
  count(geo)
```

----

What would I do with more time?

- Clean up/consolidate geo locations (a lot of subregions, where are all of these places? correlation to theme?)
- NLP on costume title and description (very messy rough text fields currently)
- Background research on what some of the groups/titles mean (a lot I've never heard of)
- Prettier visualization; perhaps interactive with more data incorporated